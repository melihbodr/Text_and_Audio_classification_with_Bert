[![Open All Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QIlNsVXXwpMp8u-BAYEW3BdUEzLbcoge#scrollTo=gZpF9_gP43PS)

Goal= Correctly guessing the classification of texts and audios


# BERT_Text_Classification

It is a text classification task implementation transformers (by HuggingFace) with BERT. It contains several parts:

--Data pre-processing

--BERT tokenization and input formating

--Train with BERT

--Evaluation

--Save and load saved model


# Text-classification-transformers

Text classification tasks are most easily encountered in the area of natural language processing and can be used in various ways.

However, the given data needs to be preprocessed and the model's data pipeline must be created according to the preprocessing.

The purpose of this Repository is to allow text classification to be easily performed with Transformers (BERT)-like models if text classification data has been preprocessed into a specific structure.

Implemented based on Huggingfcae transformers for quick and convenient implementation.


## üìù read_dataset

![image](https://user-images.githubusercontent.com/75432070/116162577-c27fee00-a6fe-11eb-8d7a-794bafd05e29.png)
3061 rows

## Unique Categories

![image](https://user-images.githubusercontent.com/75432070/116162741-138fe200-a6ff-11eb-8e6a-4ace3b632146.png)





